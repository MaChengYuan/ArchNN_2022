{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6W-qyOTPct9-"
      },
      "source": [
        "# Part 1. PyTorch introductory assignments\n",
        "\n",
        "PyTorch exercises for those who want to remember the basics of framefork."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KobPC6g8cxPN"
      },
      "outputs": [],
      "source": [
        "# main framework\n",
        "import torch\n",
        "# additional functions on tensors or networks\n",
        "from torch.nn import functional as F\n",
        "\n",
        "# work with arrays in pure python\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3P3iL68dm21"
      },
      "source": [
        "## 1.1 Tensors creation\n",
        "Tensors is a data structure optimized for automatic differentiation. In most cases, working with them is similar to working with arrays in numpy.\n",
        "\n",
        "We use `torch.tensor()` to create tensor object from pure Python and Numpy objects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_2lnqdFHG-r"
      },
      "source": [
        "### 1. From list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q44dHwvGdgtV",
        "outputId": "6f8da2f4-f4eb-45a0-fe1b-fca87601135e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n"
          ]
        }
      ],
      "source": [
        "data_lst = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
        "''' YOUR CODE HERE '''\n",
        "tensor_from_lst = torch.tensor(data_lst)\n",
        "print(tensor_from_lst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjwKxHWyIAGT"
      },
      "outputs": [],
      "source": [
        "assert(tensor_from_lst.dtype == torch.int64)\n",
        "assert(tensor_from_lst.shape == torch.Size([3, 3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HEtgbfUJJd8"
      },
      "source": [
        "### 2. From Numpy array\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3JJ7L7jJiaL",
        "outputId": "81884dc1-e00b-45fd-ae3b-b0fec3110b4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n"
          ]
        }
      ],
      "source": [
        "data_ndarray = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "''' YOUR CODE HERE '''\n",
        "tensor_from_numpy = torch.tensor(data_ndarray)\n",
        "print(tensor_from_numpy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDoWDqiPKXAT"
      },
      "outputs": [],
      "source": [
        "assert(tensor_from_numpy.dtype == torch.int64)\n",
        "assert(tensor_from_numpy.shape == torch.Size([3, 3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0y6JfgzAKYxb"
      },
      "source": [
        "You can also try to use `torch.from_numpy()` on the following array to understand the differences between this function and `torch.tensor()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIewLwK3Kxbj",
        "outputId": "7799c211-3128-4811-d011-57d51c0f0428"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n"
          ]
        }
      ],
      "source": [
        "data_ndarray2 = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "''' YOUR CODE HERE '''\n",
        "tensor_using_from_numpy = torch.from_numpy(data_ndarray2)\n",
        "print(tensor_using_from_numpy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqJs5outLhCb",
        "outputId": "89e8199f-8fa9-4456-b9bf-eada0d451e07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 2 3]\n",
            "[0 0 0]\n"
          ]
        }
      ],
      "source": [
        "tensor_from_numpy *= 0\n",
        "tensor_using_from_numpy *= 0\n",
        "print(data_ndarray[0])\n",
        "print(data_ndarray2[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJQnlGPGMp9D"
      },
      "outputs": [],
      "source": [
        "assert(all(data_ndarray[0] == [1, 2, 3]))\n",
        "assert(all(data_ndarray2[0] == [0, 0, 0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXTSVYbfNSZU"
      },
      "source": [
        "### 3. Using default values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Hz-u_gYLr27",
        "outputId": "f24948ca-38d1-4ed8-ab8e-05d20a867700"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Zero:\n",
            "tensor([[[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]]])\n"
          ]
        }
      ],
      "source": [
        "data_shape = (2, 3, 4)\n",
        "\n",
        "# Creating a tensor of a given shape filled with zeros\n",
        "tensor_zeros = torch.zeros(data_shape)\n",
        "print('Zero:\\n{}'.format(tensor_zeros))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRj4ZOSCQz-E",
        "outputId": "13c6686d-e121-46f4-f6f0-15a3b0e23684"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "one:\n",
            "tensor([[[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]]])\n",
            "rand:\n",
            "tensor([[[0.9597, 0.3407, 0.0710, 0.0312],\n",
            "         [0.9922, 0.1076, 0.0657, 0.7000],\n",
            "         [0.9763, 0.1212, 0.3323, 0.1041]],\n",
            "\n",
            "        [[0.6510, 0.8315, 0.9542, 0.3894],\n",
            "         [0.6895, 0.8401, 0.2965, 0.1798],\n",
            "         [0.7805, 0.3226, 0.2008, 0.0924]]])\n"
          ]
        }
      ],
      "source": [
        "# Create tensor of a given shape filled with ones\n",
        "''' YOUR CODE HERE '''\n",
        "tensor_ones = torch.ones(data_shape)\n",
        "print('one:\\n{}'.format(tensor_ones))\n",
        "\n",
        "# Create tensor of a given shape filled with random numbers\n",
        "''' YOUR CODE HERE '''\n",
        "tensor_rand = torch.rand(data_shape)\n",
        "print('rand:\\n{}'.format(tensor_rand))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VORnV5CrSB1C"
      },
      "outputs": [],
      "source": [
        "assert(all(tensor_ones[0][0] == torch.tensor([1., 1., 1., 1.])))\n",
        "assert(tensor_ones.shape == torch.Size(data_shape))\n",
        "assert(tensor_rand.shape == torch.Size(data_shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PfdPfD2RNkT"
      },
      "source": [
        "You can also create tensor from sequence using `torch.arange()` and then use `tensor.reshape()` function to convert data into the desired shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cBezVXLRNEs"
      },
      "outputs": [],
      "source": [
        "range_len = 24\n",
        "# Create tensor filled with sequential values from 0 to range_len\n",
        "''' YOUR CODE HERE '''\n",
        "tensor_seq = torch.arange(0, range_len)\n",
        "\n",
        "# Convert the shape of the created tensor to fit data_shape\n",
        "''' YOUR CODE HERE '''\n",
        "tensor_seq_reshaped = tensor_seq.reshape(data_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfgHhd2jVItb"
      },
      "outputs": [],
      "source": [
        "assert(tensor_seq[0] == torch.tensor(0))\n",
        "assert(tensor_seq[-1] == torch.tensor(range_len - 1))\n",
        "assert(tensor_seq.shape ==torch.Size([range_len]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lD4IBMFRsEL"
      },
      "outputs": [],
      "source": [
        "assert(tensor_seq_reshaped[0][0][0] == torch.tensor(0))\n",
        "assert(tensor_seq_reshaped[-1][-1][-1] == torch.tensor(range_len - 1))\n",
        "assert(tensor_seq_reshaped.shape == torch.Size(data_shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8iarPvOXXXz"
      },
      "source": [
        "If you want to make a tensor with a shape of another tensor, but with default values, you can use `torch.values_like()` functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiYRWNOMQJFk",
        "outputId": "662d62a4-a448-4d0f-bd9f-49821d848704"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image:\n",
            "tensor([[[0.4063, 0.9351],\n",
            "         [0.9152, 0.8261]]])\n",
            "Image_mask:\n",
            "tensor([[[0., 0.],\n",
            "         [0., 0.]]])\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.rand((1, 2, 2))\n",
        "\n",
        "# For example, you want to create a mask for the image or something filled with zeros\n",
        "tensor_mask = torch.zeros_like(tensor)\n",
        "print('Image:\\n{}'.format(tensor))\n",
        "print('Image_mask:\\n{}'.format(tensor_mask))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CQ-VUHgX7Ir"
      },
      "source": [
        "Using similar functions, create a tensor mask filled with ones and a mask filled with the random values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62UbgUOzINGK",
        "outputId": "a39f69e5-2817-494e-879e-a8a25440747a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[1., 1.],\n",
            "         [1., 1.]]])\n",
            "tensor([[[0.2443, 0.8242],\n",
            "         [0.9813, 0.2252]]])\n"
          ]
        }
      ],
      "source": [
        "# Mask, filled with ones (with a shape of tensor)\n",
        "''' YOUR CODE HERE '''\n",
        "tensor_mask_ones = torch.ones_like(tensor)\n",
        "print(tensor_mask_ones)\n",
        "\n",
        "# Mask, filled with random values (with a shape of tensor)\n",
        "''' YOUR CODE HERE '''\n",
        "tensor_mask_rand = torch.rand_like(tensor)\n",
        "print(tensor_mask_rand)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAu-GFSiYaQp"
      },
      "outputs": [],
      "source": [
        "assert(tensor_mask_ones[0][0][0] == torch.tensor(1.))\n",
        "assert(tensor_mask_ones.shape == tensor.shape)\n",
        "assert(tensor_mask_rand.shape == tensor.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_G6jrftZOsr"
      },
      "source": [
        "## 1.2 Devices\n",
        "\n",
        "Tensors can be stored in general memory, GPU memory, TPU memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpmBNwwPYu1R",
        "outputId": "400f7e79-e273-4929-d844-8adb75e0ba29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.rand((2, 5, 5))\n",
        "print(tensor.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUD2xWiTbc48"
      },
      "source": [
        "For the further assignments you should use Google Colab with GPU (Runtime -> Change Runtime Type -> Hardware Accelerating) and store tensors in GPU memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDOy0VX6bmDL"
      },
      "outputs": [],
      "source": [
        "device = ('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cteUw9WwaDT5"
      },
      "outputs": [],
      "source": [
        "# Move tensor to the GPU memory\n",
        "''' YOUR CODE HERE '''\n",
        "try:\n",
        "    tensor.to('cuda:0')\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "rNMyYsp9abgS",
        "outputId": "9ef8b1a0-ec48-4091-bfb3-dc99f645cae0"
      },
      "outputs": [
        {
          "ename": "AssertionError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-afbf9a15497f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "assert(tensor.device.type == 'cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FX-vmw5tb6jU"
      },
      "source": [
        "## 1.3 Autograd\n",
        "\n",
        "Auto differentiation is a core of ML frameworks. PyTorch can figure out the computation of gradients for a set of operations. Almost all pytorch operations are differentiable.\n",
        "\n",
        "`required_grad=True` make PyTorch to store gradients for this particular tensor. Usually, for input values this parameters is set to False - we don't want to change our real data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3mOapZqeKbJ",
        "outputId": "bbc7d9d6-ed62-42bc-e872-4a77b1bb27eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[2., 2., 2., 2.],\n",
            "         [2., 2., 2., 2.],\n",
            "         [2., 2., 2., 2.],\n",
            "         [2., 2., 2., 2.]],\n",
            "\n",
            "        [[2., 2., 2., 2.],\n",
            "         [2., 2., 2., 2.],\n",
            "         [2., 2., 2., 2.],\n",
            "         [2., 2., 2., 2.]]], grad_fn=<SubBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# define function y\n",
        "tensor = torch.ones((2, 4, 4))\n",
        "tensor.requires_grad = True\n",
        "y = 5 * tensor ** 3 - 3\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5gMYz1jas4J"
      },
      "outputs": [],
      "source": [
        "# tensor = torch.rand((2, 4, 4), requires_grad=True)\n",
        "tensor = torch.ones((2, 4, 4))\n",
        "tensor.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsQqec9DeMuB",
        "outputId": "32792978-05fc-4f93-ed59-8e891324e356"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "print(tensor.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5Tnnn-5ehDE"
      },
      "source": [
        "There is no gradient for our tensor, because we have to call `.backward() ` method of variable $y$. This method will calculate gradien of $y$ over variable tensor\n",
        "\n",
        "NOTE: gradient can be calculated only for a scalar. The output of $y$ is a tensor, we can calculate mean(), sum(), etc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTcL7kXSePLh",
        "outputId": "795e8857-698f-4e43-9a10-c78c8c450b7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[15., 15., 15., 15.],\n",
            "         [15., 15., 15., 15.],\n",
            "         [15., 15., 15., 15.],\n",
            "         [15., 15., 15., 15.]],\n",
            "\n",
            "        [[15., 15., 15., 15.],\n",
            "         [15., 15., 15., 15.],\n",
            "         [15., 15., 15., 15.],\n",
            "         [15., 15., 15., 15.]]])\n"
          ]
        }
      ],
      "source": [
        "# Call the backward method and calculate gradient for the sum of the y variable\n",
        "''' YOUR CODE HERE '''\n",
        "y.sum().backward()\n",
        "print(tensor.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4BbcuK-eRTJ"
      },
      "outputs": [],
      "source": [
        "assert(tensor.grad.shape == torch.Size([2, 4, 4]))\n",
        "assert(tensor.grad[0][0][0] == torch.tensor(15))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-N-xsoeofiFb"
      },
      "source": [
        "**NOTE:** \n",
        "* you can not run `.backward()` again without calculating y value again;\n",
        "* if you run y function one more time the gradient values for tensor variable will be summed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWjIrpwof4Pa",
        "outputId": "339767e9-293f-48c5-f57b-f583430e29ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[30., 30., 30., 30.],\n",
            "         [30., 30., 30., 30.],\n",
            "         [30., 30., 30., 30.],\n",
            "         [30., 30., 30., 30.]],\n",
            "\n",
            "        [[30., 30., 30., 30.],\n",
            "         [30., 30., 30., 30.],\n",
            "         [30., 30., 30., 30.],\n",
            "         [30., 30., 30., 30.]]])\n"
          ]
        }
      ],
      "source": [
        "# Call the backward method again and calculate gradient for the sum of the y variable\n",
        "''' YOUR CODE HERE '''\n",
        "y = 5 * tensor ** 3 - 3\n",
        "y.sum().backward()\n",
        "print(tensor.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhve93SVfLsB"
      },
      "outputs": [],
      "source": [
        "assert(tensor.grad.shape == torch.Size([2, 4, 4]))\n",
        "assert(tensor.grad[0][0][0] == torch.tensor(30))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APlEpRyTgFST"
      },
      "source": [
        "## 1.4 Neural network in PyTorch\n",
        "\n",
        "NN in PyTorch defines as a set of different layers. Each layer is a specific function:\n",
        "\n",
        "\n",
        "*   Linear layer, convolutional layer, etc\n",
        "*   Activation function\n",
        "*   Tensors operations\n",
        "\n",
        "The first type has parameters called weights and biases.The process of NN training is to change weights of NN layers so the prediction of network will match the real object.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlvtVVDmgcv6"
      },
      "source": [
        "## Linear layer\n",
        "\n",
        "[torch.nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear) takes a matrix $(N, *, H_{in})$ and produce a matrix $(N, *, H_{out})$, where\n",
        "\n",
        "$*$ means any number of additional dimensions, $H_{in}$ - input features, $H_{out}$ - output features\n",
        "\n",
        "Linear layer is a $W \\cdot x + b$ operation, where $W$ - weights of the layer and $b$ - bias. Bias can be ommited with `bias=False`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8m8BLBtOfbT6",
        "outputId": "3a7360d0-acaf-4e12-deba-2dbedbe99ed2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input shape:  torch.Size([3, 5])\n"
          ]
        }
      ],
      "source": [
        "input_tensor = torch.ones((3, 5))\n",
        "print('input shape: ', input_tensor.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQfOM30-hX37"
      },
      "source": [
        "We fed sample of data with batch_size=3 and features of each sample=5. \n",
        "\n",
        "All samples in a batch processed separately. This is true for all layers and functions of PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLpsiSGshFvb",
        "outputId": "f2465c8e-0e4d-4616-902a-ff66d9f52d99"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Linear(in_features=5, out_features=100, bias=False)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a linear layer for given data with the number of out_features=100 and ommited bias (don't forget about GPU)\n",
        "''' YOUR CODE HERE '''\n",
        "layer = torch.nn.Linear(in_features=5, out_features=100, bias=False, device='cuda:0')\n",
        "layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJepe-jlh5Pi"
      },
      "source": [
        "Let's take a look at layers parameters. \n",
        "\n",
        "`layer.paramaters()` outputs a generator of all weights and biases of this object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GS3o9IikhJoQ",
        "outputId": "d9d0c2f8-6164-4bc2-93ab-536b72910b48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'generator'>\n",
            "torch.Size([100, 5])\n"
          ]
        }
      ],
      "source": [
        "print(type(layer.parameters()))\n",
        "# iterate over layer parameters and print shapes\n",
        "for i in layer.parameters():\n",
        "    print(i.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6J6Gi3qiDIM"
      },
      "source": [
        "You should receive the following output:\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7KbPhOUiSDj"
      },
      "source": [
        "Single layer contains only one weight matrix of shape (H_out, H_in). You can access the weights of a layer directly, using `layer.weight` method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oPpsDNRiB8T",
        "outputId": "ab9f363e-e0d7-4054-adf2-b1b8d0a267fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 5])\n"
          ]
        }
      ],
      "source": [
        "print(layer.weight.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xP6UY8GioBC"
      },
      "source": [
        "You can move layer from CPU to GPU in the same way as tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlFkkXb4iZgB",
        "outputId": "6d1d8526-b7a7-4ef1-e271-deae84fe9b4a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Linear(in_features=5, out_features=100, bias=False)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "layer.to('cpu') # or layer.cpu() for simplicity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_JICUxwisUh",
        "outputId": "4d1fa2cc-cb4b-4eb6-a178-a255a5629eaf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Linear(in_features=5, out_features=100, bias=False)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "layer.to('cuda:0')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7EFV0g-i48a"
      },
      "source": [
        "### Neural Network\n",
        "\n",
        "You can write a NN as a set of layers and then apply them sequentially"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ab1xdz34iu5x",
        "outputId": "2e9b884f-7f97-4543-dc1a-343dab8814b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 3])"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_tensor = torch.rand((3, 5))\n",
        "\n",
        "# Create three sequential linear layers for the given input tensor. First two with the output 100 and the last one with the output 3.\n",
        "# Apply them sequentially and store in the output\n",
        "''' YOUR CODE HERE '''\n",
        "input = torch.nn.Linear(in_features=5, out_features=100)\n",
        "hidden_1 = torch.nn.Linear(in_features=100, out_features=100)\n",
        "output = torch.nn.Linear(in_features=100, out_features=3)\n",
        "# approx 3 lines of code here\n",
        "\n",
        "output = output(hidden_1(input(input_tensor)))\n",
        "output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zpoyRpZjEqp"
      },
      "outputs": [],
      "source": [
        "assert(output.shape == torch.Size([3, 3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HKHRg8UkLfz"
      },
      "source": [
        "### Activation and loss functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwzcN4uGkXAM"
      },
      "source": [
        "You can use different activation functions from `torch.nn` and combine them sequentially with the NN layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9J8DHXGjO1J",
        "outputId": "38b692f6-582c-442b-a946-7cc53dc90bf7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ReLU6()"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example of the activation function\n",
        "torch.nn.ReLU6()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmXDvB9Hkq7D"
      },
      "source": [
        "You can use different loss functions from `torch.nn`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMv12O20krIq"
      },
      "outputs": [],
      "source": [
        "# Example of the loss fun\n",
        "loss_function = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04nXIR3jkA1c"
      },
      "source": [
        "# Part 2. Feedforward Neural Network construction assignment "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3E6eNqIl5PM"
      },
      "source": [
        "Import all the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "TiLtxZ24mXBK"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import sklearn.datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "SEED = 0\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "device = ('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8JoJwwamJPq"
      },
      "source": [
        "To use the `plot_decision_regions` we should additionally install the `mlxtend` package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "VIAJAIG2l4Vq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58d7b1a8-cfe2-458d-bf67-78b4750c4928"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.8/dist-packages (0.14.0)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.0.2)\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.21.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from mlxtend) (57.4.0)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.1->mlxtend) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.17.1->mlxtend) (2022.7.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18->mlxtend) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18->mlxtend) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib>=1.5.1->mlxtend) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install mlxtend"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kN4gvrl5md66"
      },
      "source": [
        "## Uploading dataset\n",
        "\n",
        "Let's upload the wine dataset from sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "ElBSbXRBkKUr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78356c3c-138f-41a8-856e-ba3caaeb90f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(178, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "wine = sklearn.datasets.load_wine()\n",
        "wine.data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzmI_lNKs7M5"
      },
      "source": [
        "Create class for the dataset. Inherit a class from Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "1oTZKhTymtUE"
      },
      "outputs": [],
      "source": [
        "# Fill the WineDataset class fields\n",
        "class WineDataset():\n",
        "    def __init__(self, X, y):\n",
        "        ''' YOUR CODE HERE '''\n",
        "        self.X = torch.tensor(X, dtype=torch.float32).to('cpu')\n",
        "        self.y = torch.tensor(y, dtype=torch.float32).to('cpu')\n",
        "        self.len = X.shape[0]\n",
        "        \n",
        "        \n",
        "    \n",
        "    def __len__(self):\n",
        "        ''' YOUR CODE HERE '''\n",
        "        return self.len\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        ''' YOUR CODE HERE '''\n",
        "        return self.X[idx],self.y[idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzd8eZoUtrL5"
      },
      "source": [
        "Create train and test splits using `train_test_split` function with the following parameters:\n",
        "\n",
        "* size of test - 30%\n",
        "* using shuffle\n",
        "* using SEED constant for the random state\n",
        "\n",
        "Remember that use should use WineDataset class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "-rizvl_0tiBq"
      },
      "outputs": [],
      "source": [
        "''' YOUR CODE HERE '''\n",
        "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size = 0.3, random_state = SEED, shuffle = True)\n",
        "train_dataset = list(zip(X_train, y_train))\n",
        "test_dataset = list(zip(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "t3hIxoW7uY-D"
      },
      "outputs": [],
      "source": [
        "assert(len(train_dataset) == 124)\n",
        "assert(len(test_dataset) == 54)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-qto2JZuw4p"
      },
      "source": [
        "## Creating Feedforward network\n",
        "\n",
        "Create the FNN with the following attributes:\n",
        "* 3 linear layers\n",
        "* activation functions on your choice (the most suitable for this kind of task)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "''' YOUR CODE HERE '''\n",
        "INPUT_SIZE = 13\n",
        "OUTPUT_SIZE = 3\n",
        "\n",
        "class WineNet(nn.Module):\n",
        "    def __init__(self, n_hidden_neurons):\n",
        "        super().__init__()\n",
        "        \n",
        "        ''' YOUR CODE HERE '''\n",
        "        \n",
        "        self.hidden1 = torch.nn.Linear(INPUT_SIZE, n_hidden_neurons , dtype=np.float)\n",
        "        torch.nn.init.kaiming_uniform_(self.hidden1.weight, nonlinearity='relu')\n",
        "        self.act1 = torch.nn.ReLU()\n",
        "        # second hidden layer\n",
        "        self.hidden2 = torch.nn.Linear(n_hidden_neurons, n_hidden_neurons , dtype=np.float)\n",
        "        torch.nn.init.kaiming_uniform_(self.hidden2.weight, nonlinearity='relu')\n",
        "        self.act2 = torch.nn.ReLU()\n",
        "        # third hidden layer and output\n",
        "        self.hidden3 = torch.nn.Linear(n_hidden_neurons, OUTPUT_SIZE , dtype=np.float)\n",
        "        torch.nn.init.xavier_uniform_(self.hidden3.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ''' YOUR CODE HERE '''\n",
        "        x = self.hidden1(x)\n",
        "        x = self.act1(x)\n",
        "        # second hidden layer\n",
        "        x = self.hidden2(x)\n",
        "        x = self.act2(x)\n",
        "        # output layer\n",
        "        x = self.hidden3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    # для использования в функции plot_decision_regions\n",
        "    def predict(self, x):\n",
        "        ''' PLEASE DO NOT CHANGE THE CODE OF THIS FUNCTION '''\n",
        "        x = torch.tensor(x, dtype=torch.float32).to('cpu')\n",
        "        with torch.no_grad():\n",
        "            x = self.forward(x)\n",
        "        x = x.cpu().argmax(dim=-1)\n",
        "        x = x.data.numpy()\n",
        "        return x"
      ],
      "metadata": {
        "id": "LbHnrEWs3Egv"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "TCFnDMR3vl_a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69265e96-dc9e-45ed-cb89-49b74cd25c34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-79-38bee8dc5a20>:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  self.hidden1 = torch.nn.Linear(INPUT_SIZE, n_hidden_neurons , dtype=np.float)\n",
            "<ipython-input-79-38bee8dc5a20>:15: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  self.hidden2 = torch.nn.Linear(n_hidden_neurons, n_hidden_neurons , dtype=np.float)\n",
            "<ipython-input-79-38bee8dc5a20>:19: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  self.hidden3 = torch.nn.Linear(n_hidden_neurons, OUTPUT_SIZE , dtype=np.float)\n"
          ]
        }
      ],
      "source": [
        "model = WineNet(200) # you can change parameters here\n",
        "model = model.to('cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JB3p3LdpwAdR"
      },
      "source": [
        "## Training FNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "SU5dJkJZv6m5"
      },
      "outputs": [],
      "source": [
        "# Initialize the loss function and initialize and tune the optimizer and scheduler  \n",
        "''' YOUR CODE HERE '''\n",
        "loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-5)\n",
        "lambda1 = lambda epoch: 0.65 ** epoch\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)\n",
        "scheduler = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBn87Xy0xNSS"
      },
      "source": [
        "Write the code for the model training process.\n",
        "\n",
        "NOTE: You can memorize the best metric value and weight in the colab with the commands \n",
        "\n",
        "`torch.save(model.state_dict(), STATE_DICT_PATH)`, and `load model.load_state_dict(torch.load(STATE_DICT_PATH))`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "JB7wbCFuwSIh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227,
          "referenced_widgets": [
            "baa126a939064a679526dc391bbd955a",
            "0b71a89073214ec1b20fd244ac2c716d",
            "152bed7b7c704bffb56fbf5f5a19804e",
            "bc062bcad9a64d8db3a9a6cc2b262386",
            "77067e7d1cab4e1481230e7004d40fa6",
            "00861c1167e049948937d22c728f8f35",
            "6dfcf156abc4443b81bedcb91ab3c475",
            "b2010b26e9b447509208f0d54626f684",
            "3240263299134fbcbc97047144bb545f",
            "695171e9e67c494a8c7a33725336cecb",
            "2b3dc6cd5cf84e73bddb353b692509c9"
          ]
        },
        "outputId": "c5fbbcf0-b0b6-4f63-95ad-12b34d770781"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "baa126a939064a679526dc391bbd955a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 100.8221\t\tTest metric: 0.4074\n",
            "Test loss: 0.4427\t\tTest metric: 0.8333\n",
            "Test loss: 0.3736\t\tTest metric: 0.8704\n",
            "Test loss: 0.2731\t\tTest metric: 0.9444\n",
            "Test loss: 0.9229\t\tTest metric: 0.7407\n",
            "Test loss: 0.2975\t\tTest metric: 0.8704\n",
            "Test loss: 0.2294\t\tTest metric: 0.9259\n",
            "Test loss: 0.2334\t\tTest metric: 0.9074\n",
            "Test loss: 0.1897\t\tTest metric: 0.9630\n",
            "Test loss: 0.5676\t\tTest metric: 0.8704\n"
          ]
        }
      ],
      "source": [
        "''' YOUR CODE HERE '''\n",
        "BATCH_SIZE = 5\n",
        "EPOCHS_NUM = 1000\n",
        "\n",
        "''' PLEASE DO NOT CHANGE THE CODE OF THESE LINES '''\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
        "\n",
        "# choose any metric from sklearn for multiclass classification\n",
        "''' YOUR CODE HERE '''\n",
        "metric_fn = sklearn.metrics.accuracy_score\n",
        "\n",
        "best_metric = sklearn.metrics.f1_score\n",
        "STATE_DICT_PATH = 'best_model_state_dict.pt'\n",
        "\n",
        "for epoch in tqdm(range(EPOCHS_NUM)):\n",
        "    model.train()\n",
        "    for x, y in train_loader:\n",
        "        ''' YOUR CODE HERE '''\n",
        "        # Several lines\n",
        "        \n",
        "        pred = model(x)\n",
        "        error = loss(pred, y.flatten().long())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        error.backward() \n",
        "        optimizer.step()\n",
        "\n",
        "    if scheduler is not None:\n",
        "        scheduler.step()\n",
        "        \n",
        "    if epoch % 100 == 0:\n",
        "        model.eval()\n",
        "        test_preds = []\n",
        "        true = []\n",
        "        # with the no_grad() option, the gradients of the weights do not count\n",
        "        with torch.no_grad():\n",
        "            for x, y in test_loader:\n",
        "                ''' YOUR CODE HERE '''\n",
        "                preds = model(x)\n",
        "                test_preds.append(preds)\n",
        "                true.append(y.flatten().long())\n",
        "        \n",
        "        test_preds = torch.cat(test_preds).squeeze()\n",
        "        true = torch.cat(true).squeeze()\n",
        "        test_loss = loss(test_preds, true).item()\n",
        "        test_metric = metric_fn(true, test_preds.argmax(dim=-1))\n",
        "        \n",
        "        ''' YOUR CODE HERE '''\n",
        "        # Only if you want to save the best state\n",
        "        # no intention to save #\n",
        "        print(f'Test loss: {test_loss:0.4f}\\t\\tTest metric: {test_metric:0.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCsjlTrJxu6p"
      },
      "source": [
        "Example of the nice data plot :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "tFuu3GCjxo7K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "outputId": "af4b15ce-1666-425a-e48e-d83dc04e4794"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "float64\n",
            "int64\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-c6e5d2ff2688>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mplot_decision_regions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/mlxtend/plotting/decision_regions.py\u001b[0m in \u001b[0;36mplot_decision_regions\u001b[0;34m(X, y, clf, feature_index, filler_feature_values, filler_feature_ranges, ax, X_highlight, res, legend, hide_spines, markers, colors, scatter_kwargs, contourf_kwargs, scatter_highlight_kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiller_feature_values\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0mX_predict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiller_feature_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m     \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m     \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;31m# Plot decisoin region\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-79-38bee8dc5a20>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-79-38bee8dc5a20>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;34m''' YOUR CODE HERE '''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# second hidden layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# display decision region for all elements\n",
        "\n",
        "model.eval()\n",
        "plt.rcParams['figure.figsize'] = (10, 8)\n",
        "\n",
        "X = wine.data[:, :2].astype('float')# fix here if needed \n",
        "y = wine.target.astype('int')\n",
        "\n",
        "\n",
        "print(X.dtype)\n",
        "print(y.dtype)\n",
        "\n",
        "plot_decision_regions(X, y, clf=model, legend=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaF116Zdxsax"
      },
      "source": [
        "### Model evaluation\n",
        "\n",
        "You should create a model with the F1-score greater than 0.87"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "N4Qal9n4x5ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e57ccb89-ba52-4e07-dc86-dbbce86dc232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score on test: 0.8984770784770785\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "test_preds = []\n",
        "true = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, y in test_loader:\n",
        "        x = x.to('cpu')\n",
        "        preds = model.forward(x).cpu()\n",
        "        test_preds.append(preds)\n",
        "        true.append(y)\n",
        "test_preds = torch.cat(test_preds).squeeze()\n",
        "true = torch.cat(true).squeeze()\n",
        "test_metric = metrics.f1_score(true, test_preds.argmax(dim=-1), average='macro')\n",
        "\n",
        "print('F1-score on test:', test_metric)\n",
        "assert test_metric >= 0.87, \"You need to get f1_score greater or equal to 0.87\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-k5EMO6x695"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "baa126a939064a679526dc391bbd955a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b71a89073214ec1b20fd244ac2c716d",
              "IPY_MODEL_152bed7b7c704bffb56fbf5f5a19804e",
              "IPY_MODEL_bc062bcad9a64d8db3a9a6cc2b262386"
            ],
            "layout": "IPY_MODEL_77067e7d1cab4e1481230e7004d40fa6"
          }
        },
        "0b71a89073214ec1b20fd244ac2c716d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00861c1167e049948937d22c728f8f35",
            "placeholder": "​",
            "style": "IPY_MODEL_6dfcf156abc4443b81bedcb91ab3c475",
            "value": "100%"
          }
        },
        "152bed7b7c704bffb56fbf5f5a19804e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2010b26e9b447509208f0d54626f684",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3240263299134fbcbc97047144bb545f",
            "value": 1000
          }
        },
        "bc062bcad9a64d8db3a9a6cc2b262386": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_695171e9e67c494a8c7a33725336cecb",
            "placeholder": "​",
            "style": "IPY_MODEL_2b3dc6cd5cf84e73bddb353b692509c9",
            "value": " 1000/1000 [01:04&lt;00:00, 12.11it/s]"
          }
        },
        "77067e7d1cab4e1481230e7004d40fa6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00861c1167e049948937d22c728f8f35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dfcf156abc4443b81bedcb91ab3c475": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2010b26e9b447509208f0d54626f684": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3240263299134fbcbc97047144bb545f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "695171e9e67c494a8c7a33725336cecb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b3dc6cd5cf84e73bddb353b692509c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}